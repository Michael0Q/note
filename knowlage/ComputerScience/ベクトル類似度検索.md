# ベクトル類似度検索

## 概要

ベクトル類似度検索（Vector Similarity Search）は、テキスト、画像、音声などの非構造化データを「ベクトル」と呼ばれる数値の配列に変換し、そのベクトル間の距離や角度に基づいて類似したデータを見つけ出す技術です。この技術は、特に生成 AI の分野で注目されており、様々なアプリケーションの根幹を支えています。

## 仕組み

ベクトル類似度検索は、主に以下の 3 つの要素で構成されます。

1.  **ベクトル埋め込み (Vector Embeddings)**

    - テキストや画像などの元データを、機械学習モデル（特に深層学習モデル）を用いて高次元のベクトル空間上の点として表現します。このベクトルは、データの意味的な特徴を捉えた数値の配列です。
    - 例えば、単語の埋め込みモデル（Word2Vec や GloVe）や、文・文書の埋め込みモデル（BERT などの Transformer ベースのモデル）が利用されます。

2.  **ベクトルデータベース (Vector Database)**

    - 生成されたベクトルを効率的に格納し、高速な検索を可能にするために最適化されたデータベースです。
    - 代表的なものに、`Pinecone`, `Weaviate`, `Milvus`, `Redis` などがあります。
    - これらのデータベースは、後述する近傍探索アルゴリズムを効率的に実行するためのインデックス機能を備えています。

3.  **距離・類似度指標 (Distance Metrics)**
    - ベクトル空間における 2 つのベクトルがどの程度似ているか（または離れているか）を定量的に評価するための計算方法です。代表的な指標には以下のようなものがあります。
      - **コサイン類似度 (Cosine Similarity):** ベクトル間の角度のコサインを計算します。値が 1 に近いほど類似度が高く、ベクトルの向きが似ていることを意味します。文書の類似度判定などでよく用いられます。
      - **ユークリッド距離 (Euclidean Distance / L2 Norm):** ベクトル空間上の 2 点間の直線距離を計算します。値が小さいほど類似度が高いことを意味します。
      - **マンハッタン距離 (Manhattan Distance / L1 Norm):** 各次元の差の絶対値の総和を計算します。グリッド状の空間を移動するような距離の計算に相当します。

## 代表的なアルゴ-リズム

膨大な数のベクトルの中から類似したものを高速に探し出すために、以下のようなアルゴリズムが用いられます。

- **k-最近傍法 (k-NN / k-Nearest Neighbors)**

  - 最も基本的なアプローチで、クエリベクトルに対して、データベース内の全てのベクトルとの距離を計算し、最も距離が近い k 個のベクトルを見つけ出します。
  - 正確な結果が得られますが、データ量が多いと計算コストが非常に高くなるという課題があります。

- **近似最近傍探索 (ANN / Approximate Nearest Neighbor)**
  - 計算速度と精度のトレードオフを許容し、完全ではないものの非常に高速に「おおよそ」最も近いベクトルを見つけ出すアルゴリズム群です。大規模なデータセットに対して実用的な速度で検索を行うために不可欠です。
  - **HNSW (Hierarchical Navigable Small World):** グラフベースの代表的な ANN アルゴリズム。階層的なグラフ構造を構築することで、高速かつ高精度な検索を実現します。
  - **LSH (Locality-Sensitive Hashing):** ハッシュ関数を用いて、類似したベクトルが同じバケットに分類されやすくすることで、検索対象を絞り込みます。
  - **PQ (Product Quantization):** ベクトルをより小さな部分ベクトルに分割し、それぞれを量子化（代表ベクトルに置き換え）することで、データサイズを圧縮し、高速な距離計算を可能にします。

## 利用例

- **検索エンジン:** キーワードだけでなく、文の意味を理解して関連性の高い文書を検索するセマンティック検索。
- **推薦システム:** ユーザーの閲覧履歴や購買履歴と似た傾向を持つ他のユーザーや商品を推薦する。
- **画像検索:** ある画像と似た構図や内容を持つ画像を検索する（例：逆画像検索）。
- **質問応答システム:** ユーザーからの質問と意味的に最も近い質問と回答のペアを知識ベースから探し出す。
- **RAG (Retrieval-Augmented Generation):** 大規模言語モデルが回答を生成する際に、外部の知識源から関連性の高い情報をベクトル検索で取得し、その情報を基に回答を生成させることで、より正確で最新の回答を可能にする。

## 参考文献

- [Vector Search For AI — Part 1 — Vector Similarity Search Algorithms](https://medium.com/@serkan_ozal/vector-similarity-search-53ed42b951d9)
- [Vector Similarity Search …..Simplified - Cubed](https://blog.cubed.run/vector-similarity-search-simplified-f025409db1c1)
- [Find anything blazingly fast with Google's vector search technology](https://cloud.google.com/blog/topics/developers-practitioners/find-anything-blazingly-fast-googles-vector-search-technology)

---

## テスト

### 問題 1: ベクトル類似度検索の 3 つの主要な構成要素を挙げ、それぞれがどのような役割を果たすか簡潔に説明してください。

**回答:**
画像やテキストデータなどをベクトル化し、意味を持つ高次元のデータに変換する。vector-embetting
ベクトルを保存するのに最適化されたデータベースに上記で生成した高次元データを保存する
k-nearest-search や、などの検索手法で、最も近いベクトルのデータなどを検索する。上記データベースはそれに特化した index などを所有する。

**フィードバック:**

- **1 つ目（ベクトル埋め込み）と 2 つ目（ベクトルデータベース）**はその通りで、完璧な理解です！
- **3 つ目**は、検索アルゴリズムについて説明されていますね。これもベクトル検索の重要な要素ですが、ドキュメントで挙げられている 3 つの主要な構成要素としては、**「距離・類似度指標」**が対応します。これは、コサイン類似度やユークリッド距離といった「ベクトルの近さ」を測るための計算方法そのものを指します。検索アルゴリズムは、この指標を使って高速に類似ベクトルを見つけるための具体的な手法、と整理するとより分かりやすいです。

### 問題 2: コサイン類似度とユークリッド距離の違いについて、どのような場合にそれぞれが有効か、具体例を挙げて説明してください。

**回答:**
ううう、わからない

**フィードバック:**
大丈夫です！ここは少し専門的なので難しいですよね。

- **違いを一言で言うと:**
  - **コサイン類似度:** ベクトルの「向き」がどれだけ似ているかを見ます。角度が近いほど類似度が高いと判断します。
  - **ユークリッド距離:** ベクトル空間での 2 点間の「純粋な物理的距離」を見ます。距離が近いほど類似度が高いと判断します。
- **具体例:**
  - **コサイン類似度が有効な例:** **文書検索**です。文書の長さが違っても（例：「AI はすごい」と「人工知能は本当にすごい技術だ」）、内容の方向性（トピック）が似ていれば、類似度を高く評価できます。
  - **ユークリッド距離が有効な例:** **画像の色情報の類似検索**など、ベクトルの各要素の大きさ自体に意味がある場合に使われます。

### 問題 3: k-NN（k-最近傍法）と ANN（近似最近傍探索）の最も大きな違いは何ですか？また、ANN が大規模データセットに対して有効な理由を説明してください。

**回答:**
最近距離法は正確性？与えられたベクトルから index で最も近いベクトルを持つデータを k 個出すから、正確度が高い、一方で、ANN は index から雑にその範囲内のデータをとってくるイメージで、早い分精度が若干悪い？

**フィードバック:**
その理解でまさしく正解です！素晴らしいです。

- **違い:** ご認識の通り、k-NN は**「厳密な（正確な）」**結果を求めるのに対し、ANN は速度を重視して**「近似的（おおよそ正しい）」**な結果を返します。
- **ANN が有効な理由:** 全データと律儀に比較する k-NN と違い、ANN は「このあたりを探せば、だいたい近いやつが見つかるだろう」と賢く探索範囲を絞ることで、計算量を大幅に削減します。そのため、データが膨大になっても現実的な時間で検索できるのです。

### 問題 4: RAG（Retrieval-Augmented Generation）において、ベクトル類似度検索はどのような役割を果たしていますか？その利点を説明してください。

**回答:**

うううわからないいいい

**フィードバック:**
これも最近の重要なキーワードですね。

- **役割:** RAG において、ベクトル検索は「**検索（Retrieval）**」の部分を担当します。ユーザーから質問が来たとき、まずその質問の意図をベクトル化し、関連する情報を知識データベースからベクトル検索で高速に引っ張ってきます。
- **利点:** LLM は、その検索してきた「カンペ（文脈情報）」を見ながら回答を生成（Generation）します。これにより、LLM が知らない最新情報や専門的な情報についても回答できるようになり、**ハルシネーション（もっともらしい嘘をつく現象）を大幅に減らす**ことができます。これが最大の利点です。
