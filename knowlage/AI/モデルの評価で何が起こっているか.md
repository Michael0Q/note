# モデルの評価で何が起こっているか？

AI モデル、特に Document AI のような情報抽出モデルの性能評価は、「AI 向けのテストと自動採点」と考えることができます。

## 評価の基本的な流れ

評価は、モデルがどれだけ正確に情報を抽出できるかを客観的に測るために行われます。

1.  **テスト問題と正解の準備**

    - **テスト問題（アセット）**: モデルが一度も見たことのないドキュメント（請求書、領収書など）のセットです。これを「テストデータセット」と呼びます。
    - **正解（グラウンドトゥルース）**: 人間が事前に、テストドキュメントのどこに正しい情報（例：請求書番号、日付など）があるかをラベリングしておきます。これが「正解データ」です。

2.  **AI によるテストの実施**

    - AI モデルがテストデータセットを読み込み、情報を抽出します。これが「AI の回答」となります。

3.  **答え合わせ（採点）**
    - 「AI の回答」と「正解データ」を一つ一つ比較し、以下の 3 つのパターンに分類します。
      - **True Positive (TP)**: 正解！ - モデルが正しく情報を抽出できた。
      - **False Positive (FP)**: お手つき！ - モデルが間違った情報を抽出した。
      - **False Negative (FN)**: 見逃し！ - モデルが抽出するべき情報を見つけられなかった。

## 評価指標の計算

上記の採点結果（TP, FP, FN の数）をもとに、モデルの性能を客観的な数値で表す「評価指標」を計算します。

- **適合率 (Precision)**: AI が「抽出した」と回答したもののうち、どれだけが本当に正しかったか。この指標が高いほど、AI の回答の信頼性が高いことを意味します。
- **再現率 (Recall)**: 本来抽出されるべき情報全体のうち、どれだけを AI が見つけ出せたか。この指標が高いほど、情報の網羅性が高い（見逃しが少ない）ことを意味します。
- **F1 スコア**: 適合率と再現率のバランスを考慮した総合評価点です。

このプロセスを通じて、モデルの強みや弱点を把握し、改善につなげていきます。

---

### 関連

[[モデルパフォーマンスの評価]]
