# 概要

DocumentAI による[[ファインチューニング]]のプロセスについてまとめる。

## Document AI カスタムエクストラクタの作成方法

Document AI のカスタムエクストラクタを使用すると、特定のドキュメントタイプに合わせてカスタマイズされたデータ抽出モデルを構築できます。これにより、請求書、契約書、W-2 フォームなど、独自のドキュメントから必要な情報を高精度で抽出することが可能になります。

作成方法には、主に「生成 AI（Generative AI）を利用する方法」と「従来のカスタムモデルをトレーニングする方法」の 2 つがあります。

> **引用元:**
>
> - [Custom extractor with generative AI](https://cloud.google.com/document-ai/docs/ce-with-genai)
> - [Custom extractor mechanisms](https://cloud.google.com/document-ai/docs/ce-mechanisms)
> - [Codelabs: Document AI Workbench - Custom Document Extractor](https://codelabs.developers.google.com/codelabs/docai-custom)

---

### 作成アプローチの選択

どちらのアプローチを選択するかは、利用可能なトレーニングデータの量や求める精度によって決まります。

| トレーニング方法                   | 精度   | 労力 | 推奨トレーニングドキュメント数 | 特徴                                                                     |
| :--------------------------------- | :----- | :--- | :----------------------------- | :----------------------------------------------------------------------- |
| **ゼロショット (生成 AI)**         | 中     | 低   | 0                              | スキーマ定義のみで、事前学習済み基盤モデルを利用して抽出。               |
| **フューショット (生成 AI)**       | 中〜高 | 低   | 5〜10                          | 少数のラベル付きドキュメントで基盤モデルの性能を向上。                   |
| **ファインチューニング (生成 AI)** | 高     | 中   | 10〜50+                        | より多くのラベル付きドキュメントで基盤モデルを特定のタスクに最適化。     |
| **カスタムモデルのトレーニング**   | 高     | 高   | 各ラベル 10-50+                | 従来の機械学習モデルをゼロからトレーニング。大規模なデータセットが必要。 |

---

### 作成手順詳細

以下に、生成 AI を利用したカスタムエクストラクタ作成の一般的なステップを解説します。

#### ステップ 1: プロセッサの作成

1.  Google Cloud コンソールの Document AI `Workbench` ページに移動します。
2.  **[Create processor]** をクリックし、**[Custom extractor]** を選択します。
3.  プロセッサに名前を付け、リージョンを選択して作成します。

#### ステップ 2: スキーマ（抽出フィールド）の定義

1.  作成したプロセッサの **[Get started]** タブで **[Create new field]** を選択します。
2.  抽出したいフィールド（例：`invoice_id`, `due_date`, `total_amount`）の名前、データ型（`Text`, `Number`, `Date`, `Money`など）、出現回数（`Required once`, `Optional multiple`など）を定義します。
3.  **生成 AI を利用する場合、フィールド名と説明（Description）は非常に重要です。** モデルがフィールドの意味を理解し、精度高く抽出するためのプロンプトとして利用されるため、具体的で分かりやすい名前と説明を付けることが推奨されます。

#### ステップ 3: ドキュメントのインポートとラベリング

1.  **[Build]** タブに移動し、**[Import Documents]** をクリックします。
2.  トレーニング用とテスト用のドキュメントを Cloud Storage からインポートします。データセットは自動で `Training` と `Test` に分割（例: 80%/20%）することが推奨されます。
3.  **自動ラベリング（Auto-labeling）**:
    - インポート時に **[Import with auto-labeling]** チェックボックスをオンにし、基盤モデル（Foundation Model）を選択すると、AI が自動でラベル付けを行います。
    - 自動ラベル付けされたドキュメントは、必ず人間がレビューし、正確性を確認・修正した上で **[Mark as Labeled]** をクリックします。
4.  **手動ラベリング**:
    - ドキュメントを開き、抽出したいテキストをバウンディングボックスで囲み、対応するラベルを割り当てます。

#### ステップ 4: モデルのトレーニング

1.  **[Build]** タブで、トレーニング方法を選択します。
    - **Call foundation model**: ゼロショットまたはフューショットで、基盤モデルを直接利用して新しいプロセッサバージョンを作成します。
    - **Fine-tuning**: 十分なラベル付きデータがある場合、基盤モデルをファインチューニングして新しいバージョンを作成します。学習ステップ数（Training steps）や学習率（Learning rate multiplier）などのハイパーパラメータを調整することも可能です。
2.  バージョン名を入力し、**[Create]** をクリックしてトレーニングを開始します。トレーニングには数分から数時間かかる場合があります。

#### ステップ 5: モデルの評価

1.  トレーニングが完了したら、**[Evaluate & test]** タブに移動します。
2.  ここで、モデルのパフォーマンスを評価するための指標（F1 スコア、適合率、再現率など）を確認できます。
3.  テストドキュメントをアップロードして、実際の抽出結果を確認し、期待通りのパフォーマンスか判断します。

> より詳しい評価方法や指標については [[モデルパフォーマンスの評価]] を参照してください。

#### ステップ 6: モデルのデプロイと使用

1.  **[Manage versions]** タブに移動します。
2.  使用したいモデルのバージョンを選択し、**[Deploy]** をクリックしてデプロイします。
3.  デプロイが完了したら、そのバージョンを **[Set as default]** に設定することで、API からプロセッサ ID を指定するだけでそのバージョンが使用されるようになります。
4.  あとは、Document AI の API やクライアントライブラリを使って、ドキュメントを処理し、抽出結果を JSON 形式で受け取ることができます。

### 関連

[[転移学習]]
